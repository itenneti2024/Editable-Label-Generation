{"cells":[{"cell_type":"code","execution_count":null,"id":"5a45d5e8-25cb-420f-82ea-66f436c43e16","metadata":{"id":"5a45d5e8-25cb-420f-82ea-66f436c43e16"},"outputs":[],"source":["import os\n","import openai\n","from openai import OpenAI\n","import requests"]},{"cell_type":"code","execution_count":null,"id":"9c6a0217-f916-4c7f-8def-46231f1a05ba","metadata":{"scrolled":true,"id":"9c6a0217-f916-4c7f-8def-46231f1a05ba"},"outputs":[],"source":["# Set up your OpenAI API key\n","api_key = #placeholder\n","anthropic_api_key = #placeholder\n","\n","# Define the path to the image file\n","image_path = '/Users/yumin/Desktop/998.bmp'\n","bbox_path = '/Users/yumin/Desktop/998_detections.json'\n","text_path = '/Users/yumin/Desktop/text/998.txt'\n","barcode_path = '/Users/yumin/Desktop/barcode/998.txt'\n","\n","# prompt = \"Please analyze this image and identify metadata elements such as text, figures, barcodes, and other details. Then, based on the detected metadata, generate the corresponding ZPL code. The text file includes coordinates for each element within the image. The format is [class] [x_center] [y_center] [width] [height], where 'class 0' indicates text, 'class 1' represents barcodes, and 'class 2' indicates lines or figures. \"\n","\n","\n","# def get_zpl_code_from_image(image_path):\n","#     # Read the image file\n","#     with open(image_path, \"rb\") as image_file:\n","#         image_data = image_file.read()\n","\n","#     # Upload the image and get the ZPL code by prompting ChatGPT with an appropriate request\n","#     response = openai.Image.create_edit(\n","#         image=image_data,\n","#         prompt=prompt,\n","#         size=\"1024x1024\",\n","#         response_format=\"url\"\n","#     )\n","\n","#     if response:\n","#         print(\"ZPL Code Response:\", response[\"choices\"][0][\"text\"])\n","#     else:\n","#         print(\"Failed to retrieve the ZPL code.\")\n","\n","# # Call the function\n","# get_zpl_code_from_image(image_path)\n"]},{"cell_type":"markdown","id":"59af2174-ec6e-4fb8-9bcc-2c0c96bf121d","metadata":{"id":"59af2174-ec6e-4fb8-9bcc-2c0c96bf121d"},"source":["# OPEN AI API"]},{"cell_type":"markdown","id":"47ba2ef5-c9c1-4e1b-a7dd-b161fa20f508","metadata":{"jp-MarkdownHeadingCollapsed":true,"id":"47ba2ef5-c9c1-4e1b-a7dd-b161fa20f508"},"source":["## Baseline"]},{"cell_type":"code","execution_count":null,"id":"d54d5014-04cf-4f17-bbeb-2d8008c7c3c9","metadata":{"id":"d54d5014-04cf-4f17-bbeb-2d8008c7c3c9"},"outputs":[],"source":["from PIL import Image\n","import base64\n","import io\n","prompt = \"please detect the metadata (e.g., text, figure, barcode, and other information) in this figure, and then generate the ZPL code based on the detected metadata\"\n","def encode_image(image_path):\n","    # Open the BMP image\n","    with Image.open(image_path) as img:\n","        # Convert the image to PNG format in memory\n","        with io.BytesIO() as png_image:\n","            img.save(png_image, format=\"PNG\")\n","            png_image.seek(0)  # Go back to the beginning of the in-memory file\n","            # Encode directly to base64\n","            return base64.b64encode(png_image.getvalue()).decode('utf-8')\n","\n","\n","# Path to your image\n","# image_path = \"images/dogs/image_1.jpg\"\n","\n","# Getting the base64 string\n","base64_image = encode_image(image_path)"]},{"cell_type":"code","execution_count":null,"id":"4c8dc4cb-1e5e-434c-bd87-83596e1af734","metadata":{"id":"4c8dc4cb-1e5e-434c-bd87-83596e1af734","outputId":"18af3d1d-f35b-458f-8532-49425d3a793c"},"outputs":[{"name":"stdout","output_type":"stream","text":["To generate ZPL code for the content detected in the image, we first identify the text and barcode:\n","\n","**Detected Metadata:**\n","1. Text:\n","   - \"This format tests:\"\n","   - \"PDF417 (87), Mode: 0, CID with valid characters\"\n","\n","2. Barcode:\n","   - PDF417\n","\n","**ZPL Code:**\n","\n","```zpl\n","^XA\n","^FO50,50^ADN,36,20^FDThis format tests:^FS\n","^FO50,100^ADN,36,20^FDPDF417 (87), Mode: 0, CID with valid characters^FS\n","^FO50,150^B7N,8,10^FD1234567890^FS\n","^XZ\n","```\n","\n","**Explanation:**\n","- `^XA` and `^XZ` are the start and end commands for a ZPL label.\n","- `^FO` sets the field origin, a position on the label.\n","- `^ADN,36,20` sets the font type and size.\n","- `^FD` specifies the field data to be printed.\n","- `^B7N,8,10` specifies a PDF417 barcode. The parameters define the barcode characteristics, such as height, security level etc.\n","- The `^FD1234567890^FS` in the barcode section is a placeholder for barcode data. Adjust it according to the actual data encoded in the image if needed.\n"]}],"source":["from openai import OpenAI\n","import base64\n","\n","client = OpenAI(api_key=api_key)\n","# client.api_key = api_key\n","\n","\n","\n","response = client.chat.completions.create(\n","    model=\"gpt-4o\",\n","    messages=[\n","        {\n","            \"role\": \"user\",\n","            \"content\": [\n","                {\"type\": \"text\", \"text\": f\"{prompt}\"},\n","                {\n","                    \"type\": \"image_url\",\n","                    \"image_url\": {\n","                        \"url\": f\"data:image/jpeg;base64,{base64_image}\",\n","                        # \"url\": \"https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg\",\n","                    }\n","                },\n","            ],\n","        }\n","    ],\n","    max_tokens=3000,\n",")\n","\n","print(response.choices[0].message.content)\n"]},{"cell_type":"markdown","id":"6ad03985-11f7-465c-9826-edb260e1fea6","metadata":{"jp-MarkdownHeadingCollapsed":true,"id":"6ad03985-11f7-465c-9826-edb260e1fea6"},"source":["## with Coordinates Information"]},{"cell_type":"code","execution_count":null,"id":"2a2f670a-d204-4ce2-b6f0-49fcbcd918c2","metadata":{"id":"2a2f670a-d204-4ce2-b6f0-49fcbcd918c2"},"outputs":[],"source":["prompt = \"\"\"please do the following steps to generate the ZPL code:\n","1/ detect the metadata in the uploaded image, including text, figure, barcode, and other information.\n","2/ Assign the coordinates to the detected metadata using the json_data. Do not use the \"class\". Only use the \"bbox\" for the coordinates of a metadata. The json file can contain less information than the bmp file, so do not rely on the json file.\n","3/ based on the detected metadata and bounding box for the metadata, generate the ZPL code.\n","\"\"\"\n","\n","\n","from PIL import Image\n","import base64\n","import io\n","\n","def encode_image(image_path):\n","    # Open the BMP image\n","    with Image.open(image_path) as img:\n","        # Convert the image to PNG format in memory\n","        with io.BytesIO() as png_image:\n","            img.save(png_image, format=\"PNG\")\n","            png_image.seek(0)  # Go back to the beginning of the in-memory file\n","            # Encode directly to base64\n","            return base64.b64encode(png_image.getvalue()).decode('utf-8')\n","\n","\n","# Path to your image\n","# image_path = \"images/dogs/image_1.jpg\"\n","\n","# Getting the base64 string\n","base64_image = encode_image(image_path)"]},{"cell_type":"code","execution_count":null,"id":"48cc6029-aefb-420c-9758-1dbe1c025213","metadata":{"id":"48cc6029-aefb-420c-9758-1dbe1c025213","outputId":"0df16ab0-e7b1-429d-9168-a292d6ee4042"},"outputs":[{"name":"stdout","output_type":"stream","text":["To generate the ZPL code based on the image and JSON data provided, we'll perform the following steps:\n","\n","### Detected Metadata\n","From the image, we detect:\n","- **Text**: \"PDF417 (8?); Mode: 0, C10 with valid characters\"\n","- **Barcode**: A barcode located as per the given JSON\n","\n","### Assign Coordinates\n","Using the JSON data, the coordinates for the text and barcode are:\n","\n","1. **Text**\n","   - Coordinates: `[15, 32, 294, 32]`\n","   - Start Point: `(15, 32)`\n","  \n","2. **Barcode**\n","   - Coordinates: `[15, 89, 196, 94]`\n","   - Start Point: `(15, 89)`\n","\n","### Generate ZPL Code\n","Now, we use the detected data and their coordinates to generate the ZPL code.\n","\n","```zpl\n","^XA\n","^FO15,32^A0N,30,30^FDThis format tests:^FS\n","^FO15,52^A0N,30,30^FDPDF417 (8?); Mode: 0, C10 with valid characters^FS\n","^FO15,89^BY2^B7N,3,10,,N^FD<The Barcode Data Here>^FS\n","^XZ\n","```\n","\n","### Explanation\n","- `^XA`: Start the ZPL code.\n","- `^FOx,y`: Field Origin at coordinates (x, y).\n","- `^A0N,h,w`: Font selection with height (h) and width (w).\n","- `^FDtext^FS`: Field Data containing the text.\n","- `^BYw`: Set barcode module width.\n","- `^B7`: Use PDF417 barcode.\n","- `^XZ`: End the ZPL code.\n","\n","Replace `<The Barcode Data Here>` with the actual data encoded by the detected barcode. If the barcode data is not known, it must be extracted through barcode scanning from the image.\n"]}],"source":["from openai import OpenAI\n","import base64\n","\n","client = OpenAI(api_key=api_key)\n","# client.api_key = api_key\n","\n","import json\n","with open(bbox_path, 'r') as file:\n","    bbox_data = json.load(file)\n","\n","# Convert the bbox_data to a JSON string\n","json_string = json.dumps(bbox_data)\n","\n","\n","response = client.chat.completions.create(\n","    model=\"gpt-4o\",\n","    messages=[\n","        {\n","            \"role\": \"user\",\n","            \"content\": [\n","                {\"type\": \"text\", \"text\": f\"{prompt}json_data: f{json_string}\"},\n","                {\n","                    \"type\": \"image_url\",\n","                    \"image_url\": {\n","                        \"url\": f\"data:image/jpeg;base64,{base64_image}\",\n","                        # \"url\": \"https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg\",\n","                    }\n","                },\n","                # {\n","                #     \"type\": \"json_data\",\n","                #     \"json_data\": bbox_json_string\n","                # }\n","            ],\n","        }\n","    ],\n","    max_tokens=3000,\n",")\n","\n","print(response.choices[0].message.content)"]},{"cell_type":"markdown","id":"04bb39b8-5078-496c-a54a-e1e747c3e8b8","metadata":{"id":"04bb39b8-5078-496c-a54a-e1e747c3e8b8"},"source":["## with Coordinates Information and Text"]},{"cell_type":"code","execution_count":null,"id":"8e5b184f-2823-4df1-b6a8-204ed99d8721","metadata":{"id":"8e5b184f-2823-4df1-b6a8-204ed99d8721","outputId":"9bdb8206-1ca5-4fa9-be20-61ca80c1bbce"},"outputs":[{"name":"stdout","output_type":"stream","text":["Detected Text: PDF417 (8?); Mode: 0, C10 with valid characters\n"]}],"source":["prompt = \"\"\"please do the following steps to generate the ZPL code:\n","1/ detect the metadata in the uploaded image, including text, figure, barcode, and other information.\n","2/ make sure the text in the detected metadata is the same as the text_data. If they are not the same, use the text_data.\n","3/ Assign the coordinates to the detected metadata using the json_data. Do not use the \"class\". Only use the \"bbox\" for the coordinates of a metadata. The json file can contain less information than the bmp file, so do not rely on the json file.\n","4/ based on the detected metadata and bounding box for the metadata, generate the ZPL code.\n","\"\"\"\n","\n","# Initialize a variable to store the detected text\n","detected_text = \"\"\n","\n","# Open and read the file\n","with open(text_path, 'r') as file:\n","    for line in file:\n","        # Look for the line that contains \"Detected Text:\"\n","        if line.startswith(\"Detected Text:\"):\n","            # Extract the text after \"Detected Text:\"\n","            detected_text = line.split(\"Detected Text:\")[1].strip()\n","            break\n","\n","# Print or use the extracted detected text\n","print(\"Detected Text:\", detected_text)\n","\n","\n","from PIL import Image\n","import base64\n","import io\n","\n","def encode_image(image_path):\n","    # Open the BMP image\n","    with Image.open(image_path) as img:\n","        # Convert the image to PNG format in memory\n","        with io.BytesIO() as png_image:\n","            img.save(png_image, format=\"PNG\")\n","            png_image.seek(0)  # Go back to the beginning of the in-memory file\n","            # Encode directly to base64\n","            return base64.b64encode(png_image.getvalue()).decode('utf-8')\n","\n","\n","# Path to your image\n","# image_path = \"images/dogs/image_1.jpg\"\n","\n","# Getting the base64 string\n","base64_image = encode_image(image_path)"]},{"cell_type":"code","execution_count":null,"id":"972fb2eb-581f-4459-92a5-cd0138b31b53","metadata":{"id":"972fb2eb-581f-4459-92a5-cd0138b31b53","outputId":"341940c8-97a5-4896-fa6e-7c35291a6134"},"outputs":[{"name":"stdout","output_type":"stream","text":["To generate the ZPL code, follow these steps:\n","\n","1. **Detect Metadata:**\n","   - From the image, identify the text and barcode.\n","\n","2. **Verify Text:**\n","   - Ensure the detected text matches the `text_data`. If not, use the `text_data`.\n","\n","3. **Assign Coordinates:**\n","   - Use the `bbox` from `json_data` to assign coordinates to the metadata.\n","\n","4. **Generate ZPL Code:**\n","\n","   - **Text:**\n","     - Coordinates from `json_data`: `[15, 32, 294, 32]`\n","     - Use `text_data`: `PDF417 (8?); Mode: 0, C10 with valid characters`\n","\n","   - **Barcode:**\n","     - Coordinates from `json_data`: `[15, 89, 196, 94]`\n","\n","Here is the ZPL code:\n","\n","```zpl\n","^XA\n","^FO15,32^A0N,30,30^FDThis format tests:^FS\n","^FO15,62^A0N,30,30^FDPDF417 (8?); Mode: 0, C10 with valid characters^FS\n","^FO15,89^BY2\n","^B7N,5,200^FD1234567890^FS\n","^XZ\n","```\n","\n","- `^XA` and `^XZ` are the start and end of the label format.\n","- `^FO` sets the field origin (x, y).\n","- `^A0N` sets the font and size.\n","- `^FD` defines the field data (text).\n","- `^BY` sets the barcode field default module width.\n","- `^B7` specifies the PDF417 barcode type.\n","\n","Adjust the barcode data (`^FD1234567890^FS`) as needed for your specific use case.\n"]}],"source":["from openai import OpenAI\n","import base64\n","\n","client = OpenAI(api_key=api_key)\n","# client.api_key = api_key\n","\n","import json\n","with open(bbox_path, 'r') as file:\n","    bbox_data = json.load(file)\n","\n","# Convert the bbox_data to a JSON string\n","json_string = json.dumps(bbox_data)\n","\n","\n","response = client.chat.completions.create(\n","    model=\"gpt-4o\",\n","    messages=[\n","        {\n","            \"role\": \"user\",\n","            \"content\": [\n","                {\"type\": \"text\", \"text\": f\"{prompt}\\njson_data: f{json_string}\\ntext_data: f{detected_text}\"},\n","                {\n","                    \"type\": \"image_url\",\n","                    \"image_url\": {\n","                        \"url\": f\"data:image/jpeg;base64,{base64_image}\",\n","                        # \"url\": \"https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg\",\n","                    }\n","                },\n","                # {\n","                #     \"type\": \"json_data\",\n","                #     \"json_data\": bbox_json_string\n","                # }\n","            ],\n","        }\n","    ],\n","    max_tokens=3000,\n","    temperature=0,\n",")\n","\n","print(response.choices[0].message.content)"]},{"cell_type":"markdown","id":"0b265985-83a6-428c-ac49-4cc2a3f5afa7","metadata":{"id":"0b265985-83a6-428c-ac49-4cc2a3f5afa7"},"source":["## with Coordinates Information, Text and Barcode"]},{"cell_type":"code","execution_count":null,"id":"76c0e88d-a81b-4213-8222-38892ee3cd3b","metadata":{"id":"76c0e88d-a81b-4213-8222-38892ee3cd3b","outputId":"1938d776-83c6-431d-d0a0-ba2102477b48"},"outputs":[{"name":"stdout","output_type":"stream","text":["Detected Text: PDF417 (8?); Mode: 0, C10 with valid characters\n","Detected Barcode: 1\n"]}],"source":["prompt = \"\"\"please do the following steps to generate the ZPL code:\n","1/ detect the metadata in the uploaded image, including text, figure, barcode, and other information.\n","2/ make sure the text in the detected metadata is the same as the text_data. If they are not the same, use the text_data.\n","3/ the number of barcode you should detect in the metadata is barcode_number.\n","4/ Assign the coordinates to the detected metadata using the json_data. Do not use the \"class\". Only use the \"bbox\" for the coordinates of a metadata. The json file can contain less information than the bmp file, so do not rely on the json file.\n","5/ based on the detected metadata and bounding box for the metadata, generate the ZPL code.\n","\"\"\"\n","\n","# Initialize a variable to store the detected text\n","detected_text = \"\"\n","\n","# Open and read the file\n","with open(text_path, 'r') as file:\n","    for line in file:\n","        # Look for the line that contains \"Detected Text:\"\n","        if line.startswith(\"Detected Text:\"):\n","            # Extract the text after \"Detected Text:\"\n","            detected_text = line.split(\"Detected Text:\")[1].strip()\n","            break\n","\n","# Print or use the extracted detected text\n","print(\"Detected Text:\", detected_text)\n","\n","# Open and read the file\n","with open(barcode_path, 'r') as file:\n","    for line in file:\n","        # Look for the line that contains \"Detected Text:\"\n","        if line.startswith(\"Total Barcodes in Image:\"):\n","            # Extract the text after \"Detected Text:\"\n","            detected_barcode = line.split(\"Total Barcodes in Image:\")[1].strip()\n","            break\n","\n","# Print or use the extracted detected text\n","print(\"Detected Barcode:\", detected_barcode)\n","\n","\n","\n","\n","from PIL import Image\n","import base64\n","import io\n","\n","def encode_image(image_path):\n","    # Open the BMP image\n","    with Image.open(image_path) as img:\n","        # Convert the image to PNG format in memory\n","        with io.BytesIO() as png_image:\n","            img.save(png_image, format=\"PNG\")\n","            png_image.seek(0)  # Go back to the beginning of the in-memory file\n","            # Encode directly to base64\n","            return base64.b64encode(png_image.getvalue()).decode('utf-8')\n","\n","\n","# Path to your image\n","# image_path = \"images/dogs/image_1.jpg\"\n","\n","# Getting the base64 string\n","base64_image = encode_image(image_path)"]},{"cell_type":"code","execution_count":null,"id":"e48659ff-3638-4efd-83f8-bc2d5cf7838c","metadata":{"id":"e48659ff-3638-4efd-83f8-bc2d5cf7838c","outputId":"e8a80e6a-9b6a-45f0-d0eb-6a2d593c0b37"},"outputs":[{"name":"stdout","output_type":"stream","text":["To generate the ZPL code, follow these steps:\n","\n","1. **Detect Metadata:**\n","   - The image contains text and a barcode.\n","\n","2. **Verify Text:**\n","   - The detected text in the image is: \"PDF417 (8?); Mode: 0, C10 with valid characters\"\n","   - The `text_data` is: \"PDF417 (8?); Mode: 0, C10 with valid characters\"\n","   - The text matches, so no changes are needed.\n","\n","3. **Barcode Detection:**\n","   - The image contains 1 barcode, which matches the `barcode_number`.\n","\n","4. **Assign Coordinates:**\n","   - Use the `bbox` from `json_data` for coordinates:\n","     - Text: `[15, 32, 294, 32]`\n","     - Barcode: `[15, 89, 196, 94]`\n","\n","5. **Generate ZPL Code:**\n","\n","```zpl\n","^XA\n","^FO15,32^A0N,30,30^FDThis format tests:^FS\n","^FO15,64^A0N,30,30^FDPDF417 (8?); Mode: 0, C10 with valid characters^FS\n","^FO15,89^B7N,5,5,5,5,5^FD1234567890^FS\n","^XZ\n","```\n","\n","- `^XA` and `^XZ` are the start and end of the ZPL code.\n","- `^FO` sets the field origin (x, y).\n","- `^A0N` sets the font and size for text.\n","- `^FD` specifies the data to print.\n","- `^B7N` is used for PDF417 barcodes, with parameters for module width, row height, etc.\n","\n","This ZPL code should accurately represent the detected metadata from the image.\n"]}],"source":["from openai import OpenAI\n","import base64\n","\n","client = OpenAI(api_key=api_key)\n","# client.api_key = api_key\n","\n","import json\n","with open(bbox_path, 'r') as file:\n","    bbox_data = json.load(file)\n","\n","# Convert the bbox_data to a JSON string\n","json_string = json.dumps(bbox_data)\n","\n","\n","response = client.chat.completions.create(\n","    model=\"gpt-4o\",\n","    messages=[\n","        {\n","            \"role\": \"user\",\n","            \"content\": [\n","                {\"type\": \"text\", \"text\": f\"{prompt}\\njson_data: f{json_string}\\ntext_data: f{detected_text}\\nbarcode_number: f{detected_barcode}\"},\n","                {\n","                    \"type\": \"image_url\",\n","                    \"image_url\": {\n","                        \"url\": f\"data:image/jpeg;base64,{base64_image}\",\n","                        # \"url\": \"https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg\",\n","                    }\n","                },\n","                # {\n","                #     \"type\": \"json_data\",\n","                #     \"json_data\": bbox_json_string\n","                # }\n","            ],\n","        }\n","    ],\n","    max_tokens=3000,\n","    temperature=0,\n",")\n","\n","print(response.choices[0].message.content)"]},{"cell_type":"code","execution_count":null,"id":"0300c2c5-1703-4d39-94bf-8866877a5c2a","metadata":{"id":"0300c2c5-1703-4d39-94bf-8866877a5c2a"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"4f890470-5652-4530-bdc1-771c61d04bd8","metadata":{"id":"4f890470-5652-4530-bdc1-771c61d04bd8"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"286157fb-1d5f-4c3c-849d-0b0902809be8","metadata":{"id":"286157fb-1d5f-4c3c-849d-0b0902809be8"},"outputs":[],"source":[]},{"cell_type":"markdown","id":"c075f698-dbef-42f1-b371-a7b3459608a5","metadata":{"jp-MarkdownHeadingCollapsed":true,"id":"c075f698-dbef-42f1-b371-a7b3459608a5"},"source":["# Anthropic"]},{"cell_type":"code","execution_count":null,"id":"80b940e2-b7ff-47b5-8462-00985ee5bd21","metadata":{"id":"80b940e2-b7ff-47b5-8462-00985ee5bd21","outputId":"e03d75a4-d5eb-4060-d0e4-2882a6f6b234"},"outputs":[{"name":"stdout","output_type":"stream","text":["From the image, I can detect:\n","\n","1. Text header: \"This format tests:\"\n","2. Format specification: \"PDF417 (3D), Mode: 0, C10 with valid characters\"\n","3. A PDF417 2D barcode\n","\n","To generate ZPL code for this, I would recommend:\n","\n","```\n","^XA\n","^FO50,50\n","^A0N,30,30\n","^FDThis format tests:^FS\n","^FO50,90\n","^A0N,25,25\n","^FDPDF417 (3D), Mode: 0, C10 with valid characters^FS\n","^FO50,130\n","^BY3\n","^B7N,10,0,,,N\n","^FDYour_PDF417_Data^FS\n","^XZ\n","```\n","\n","Where:\n","- ^XA starts the label format\n","- ^FO sets the field origin (x,y coordinates)\n","- ^A0N sets the font\n","- ^FD is the field data\n","- ^FS marks the field separator\n","- ^BY sets the bar code field defaults\n","- ^B7N specifies PDF417 barcode type\n","- ^XZ ends the label format\n","\n","Note: The actual data content of the PDF417 barcode isn't visible in the image, so I've used \"Your_PDF417_Data\" as a placeholder. You would need to replace this with the actual data you want to encode in the barcode.\n"]}],"source":["import anthropic\n","\n","client = anthropic.Anthropic(api_key=anthropic_api_key)\n","\n","message = client.messages.create(\n","    model=\"claude-3-5-sonnet-20241022\",\n","    max_tokens=1024,\n","    messages=[\n","        {\n","            \"role\": \"user\",\n","            \"content\": [\n","                {\n","                    \"type\": \"image\",\n","                    \"source\": {\n","                        \"type\": \"base64\",\n","                        \"media_type\":\"image/png\",\n","                        \"data\": base64_image,\n","                    },\n","                },\n","                {\n","                    \"type\": \"text\",\n","                    \"text\": prompt\n","                }\n","            ],\n","        }\n","    ],\n",")\n","print(message.content[0].text)\n"]},{"cell_type":"markdown","id":"8b050fa9-87c1-4cfc-bd5e-ee1e27493ab1","metadata":{"id":"8b050fa9-87c1-4cfc-bd5e-ee1e27493ab1"},"source":[]},{"cell_type":"code","execution_count":null,"id":"7fe3dd21-c988-4381-949a-9a6674d8a5ff","metadata":{"id":"7fe3dd21-c988-4381-949a-9a6674d8a5ff"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"c4992c4a-5c3a-415c-929b-c1729467c999","metadata":{"id":"c4992c4a-5c3a-415c-929b-c1729467c999"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"a380ff16-8598-4123-8261-aac919fdef92","metadata":{"id":"a380ff16-8598-4123-8261-aac919fdef92"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"3fbcd7a5-4188-435e-a272-bad918255db2","metadata":{"id":"3fbcd7a5-4188-435e-a272-bad918255db2"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"ddabafda-5a78-43b9-9532-6e2b5023eb30","metadata":{"id":"ddabafda-5a78-43b9-9532-6e2b5023eb30"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"dfacbf30-813d-42c0-bdec-aeba4149aa5b","metadata":{"id":"dfacbf30-813d-42c0-bdec-aeba4149aa5b"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"fd443811-f32f-4ea3-bd90-b5c481f04444","metadata":{"id":"fd443811-f32f-4ea3-bd90-b5c481f04444"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"f75f9a95-2314-416b-b255-146dc17aaaa6","metadata":{"id":"f75f9a95-2314-416b-b255-146dc17aaaa6"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.8"},"colab":{"provenance":[],"collapsed_sections":["47ba2ef5-c9c1-4e1b-a7dd-b161fa20f508","6ad03985-11f7-465c-9826-edb260e1fea6","04bb39b8-5078-496c-a54a-e1e747c3e8b8","0b265985-83a6-428c-ac49-4cc2a3f5afa7","c075f698-dbef-42f1-b371-a7b3459608a5"]}},"nbformat":4,"nbformat_minor":5}